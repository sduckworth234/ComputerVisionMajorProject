{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e05f8c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not read video\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@140.261] global cap_gstreamer.cpp:1436 open OpenCV | GStreamer warning: Error opening bin: no element \"data\"\n",
      "[ WARN:0@140.261] global cap_gstreamer.cpp:1173 isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO('yolov8n.pt')  # Use nano model for speed\n",
    "\n",
    "# Load video\n",
    "video_path = 'data/full_video/tennis_full_video.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Read first frame\n",
    "ret, frame = cap.read()\n",
    "if not ret:\n",
    "    print(\"Error: Could not read video\")\n",
    "else:\n",
    "    # Apply the same crop as court_roi\n",
    "    cropped_frame = frame\n",
    "    \n",
    "    # Detect people in the cropped frame\n",
    "    results = model(cropped_frame, classes=[0], verbose=False)  # class 0 is 'person'\n",
    "    \n",
    "    # Get detections and sort by confidence\n",
    "    detections = results[0].boxes\n",
    "    if len(detections) > 0:\n",
    "        # Convert to numpy for easier handling\n",
    "        boxes = detections.xyxy.cpu().numpy()\n",
    "        confidences = detections.conf.cpu().numpy()\n",
    "        \n",
    "        # Sort by confidence and take top 2\n",
    "        sorted_indices = np.argsort(confidences)[::-1]\n",
    "        top_2_indices = sorted_indices[:min(2, len(sorted_indices))]\n",
    "        \n",
    "        # Draw bounding boxes on cropped frame\n",
    "        result_frame = cropped_frame.copy()\n",
    "        colors = [(255, 0, 0), (0, 255, 0)]  # Red and Green for 2 players\n",
    "        \n",
    "        for i, idx in enumerate(top_2_indices):\n",
    "            x1, y1, x2, y2 = boxes[idx].astype(int)\n",
    "            conf = confidences[idx]\n",
    "            \n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(result_frame, (x1, y1), (x2, y2), colors[i], 2)\n",
    "            \n",
    "            # Add label\n",
    "            label = f'Player {i+1}: {conf:.2f}'\n",
    "            cv2.putText(result_frame, label, (x1, y1 - 10),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, colors[i], 2)\n",
    "        \n",
    "        # Display result\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.imshow(cv2.cvtColor(result_frame, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f'Player Tracking - {len(top_2_indices)} players detected')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Detected {len(top_2_indices)} players\")\n",
    "        for i, idx in enumerate(top_2_indices):\n",
    "            print(f\"Player {i+1}: Confidence = {confidences[idx]:.2f}\")\n",
    "    else:\n",
    "        print(\"No players detected in frame\")\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.imshow(cv2.cvtColor(cropped_frame, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('No players detected')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "070ec261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Load video\n",
    "cap = cv2.VideoCapture('../data/full_video/tennis_full_video.mp4')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Crop to court ROI\n",
    "    cropped_frame = frame\n",
    "    \n",
    "    # Detect people\n",
    "    results = model(cropped_frame, classes=[0], verbose=False)\n",
    "    detections = results[0].boxes\n",
    "    \n",
    "    # Draw on frame\n",
    "    if len(detections) > 0:\n",
    "        boxes = detections.xyxy.cpu().numpy()\n",
    "        confidences = detections.conf.cpu().numpy()\n",
    "        \n",
    "        # Get top 2 players by confidence\n",
    "        sorted_indices = np.argsort(confidences)[::-1][:2]\n",
    "        \n",
    "        # Assign players based on vertical position\n",
    "        # Player 2 (green) = top half (y < 100)\n",
    "        # Player 1 (red) = bottom half (y >= 100)\n",
    "        players = []\n",
    "        for idx in sorted_indices:\n",
    "            x1, y1, x2, y2 = boxes[idx].astype(int)\n",
    "            center_y = (y1 + y2) / 2\n",
    "            \n",
    "            if center_y < 200:\n",
    "                player_id = 2  # Top player\n",
    "                color = (0, 255, 0)  # Green\n",
    "            else:\n",
    "                player_id = 1  # Bottom player\n",
    "                color = (255, 0, 0)  # Red\n",
    "            \n",
    "            players.append((x1, y1, x2, y2, player_id, color))\n",
    "        \n",
    "        # Draw bounding boxes\n",
    "        for x1, y1, x2, y2, player_id, color in players:\n",
    "            cv2.rectangle(cropped_frame, (x1, y1), (x2, y2), color, 2)\n",
    "            # centre of mass\n",
    "            center_x = (x1 + x2) / 2\n",
    "            center_y = (y1 + y2) / 2\n",
    "            cv2.circle(cropped_frame, (int(center_x), int(center_y)), 5, color, -1)\n",
    "            cv2.putText(cropped_frame, f'P{player_id}', (x1, y1-10),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "    \n",
    "    # Display\n",
    "    cv2.imshow('Player Tracking', cropped_frame)\n",
    "    \n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samvision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
